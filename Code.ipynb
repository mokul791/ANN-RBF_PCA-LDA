{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6948,
     "status": "ok",
     "timestamp": 1564883043274,
     "user": {
      "displayName": "Shanto Paul",
      "photoUrl": "https://lh5.googleusercontent.com/-S7KXSa0Wfc8/AAAAAAAAAAI/AAAAAAAAAbA/psQRjrN7I7w/s64/photo.jpg",
      "userId": "14781007155831330088"
     },
     "user_tz": 240
    },
    "id": "4GkrLcHuHcTa",
    "outputId": "a515fa94-34ac-4421-f458-666f7ad3436a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7040,
     "status": "ok",
     "timestamp": 1564883043378,
     "user": {
      "displayName": "Shanto Paul",
      "photoUrl": "https://lh5.googleusercontent.com/-S7KXSa0Wfc8/AAAAAAAAAAI/AAAAAAAAAbA/psQRjrN7I7w/s64/photo.jpg",
      "userId": "14781007155831330088"
     },
     "user_tz": 240
    },
    "id": "RTxxxPVWMOCI",
    "outputId": "a5bcea5f-769e-468b-f6de-6178f35170a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID NUMBER</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>rv_IF1</th>\n",
       "      <th>rv_IF2</th>\n",
       "      <th>rv_IF3</th>\n",
       "      <th>rv_IF4</th>\n",
       "      <th>rv_IF5</th>\n",
       "      <th>rv_IF6</th>\n",
       "      <th>rv_IF7</th>\n",
       "      <th>rv_IF8</th>\n",
       "      <th>...</th>\n",
       "      <th>rv_IF21</th>\n",
       "      <th>rv_IF22</th>\n",
       "      <th>rv_IF23</th>\n",
       "      <th>rv_IF24</th>\n",
       "      <th>rv_IF25</th>\n",
       "      <th>rv_IF26</th>\n",
       "      <th>rv_IF27</th>\n",
       "      <th>rv_IF28</th>\n",
       "      <th>rv_IF29</th>\n",
       "      <th>rv_IF30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID NUMBER CLASS  rv_IF1  rv_IF2  rv_IF3  rv_IF4   rv_IF5   rv_IF6  rv_IF7  \\\n",
       "0     842302     M   17.99   10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1     842517     M   20.57   17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2   84300903     M   19.69   21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3   84348301     M   11.42   20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4   84358402     M   20.29   14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "    rv_IF8  ...  rv_IF21  rv_IF22  rv_IF23  rv_IF24  rv_IF25  rv_IF26  \\\n",
       "0  0.14710  ...    25.38    17.33   184.60   2019.0   0.1622   0.6656   \n",
       "1  0.07017  ...    24.99    23.41   158.80   1956.0   0.1238   0.1866   \n",
       "2  0.12790  ...    23.57    25.53   152.50   1709.0   0.1444   0.4245   \n",
       "3  0.10520  ...    14.91    26.50    98.87    567.7   0.2098   0.8663   \n",
       "4  0.10430  ...    22.54    16.67   152.20   1575.0   0.1374   0.2050   \n",
       "\n",
       "   rv_IF27  rv_IF28  rv_IF29  rv_IF30  \n",
       "0   0.7119   0.2654   0.4601  0.11890  \n",
       "1   0.2416   0.1860   0.2750  0.08902  \n",
       "2   0.4504   0.2430   0.3613  0.08758  \n",
       "3   0.6869   0.2575   0.6638  0.17300  \n",
       "4   0.4000   0.1625   0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "raw_data = pd.read_csv('wdbc.csv')\n",
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7237,
     "status": "ok",
     "timestamp": 1564883043580,
     "user": {
      "displayName": "Shanto Paul",
      "photoUrl": "https://lh5.googleusercontent.com/-S7KXSa0Wfc8/AAAAAAAAAAI/AAAAAAAAAbA/psQRjrN7I7w/s64/photo.jpg",
      "userId": "14781007155831330088"
     },
     "user_tz": 240
    },
    "id": "Z65UblxzHcTg",
    "outputId": "5411dd87-fa6e-4b68-e8b4-09a1f20bb7b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID NUMBER</th>\n",
       "      <th>rv_IF1</th>\n",
       "      <th>rv_IF2</th>\n",
       "      <th>rv_IF3</th>\n",
       "      <th>rv_IF4</th>\n",
       "      <th>rv_IF5</th>\n",
       "      <th>rv_IF6</th>\n",
       "      <th>rv_IF7</th>\n",
       "      <th>rv_IF8</th>\n",
       "      <th>rv_IF9</th>\n",
       "      <th>...</th>\n",
       "      <th>rv_IF22</th>\n",
       "      <th>rv_IF23</th>\n",
       "      <th>rv_IF24</th>\n",
       "      <th>rv_IF25</th>\n",
       "      <th>rv_IF26</th>\n",
       "      <th>rv_IF27</th>\n",
       "      <th>rv_IF28</th>\n",
       "      <th>rv_IF29</th>\n",
       "      <th>rv_IF30</th>\n",
       "      <th>NEW_CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>925291</td>\n",
       "      <td>11.51</td>\n",
       "      <td>23.93</td>\n",
       "      <td>74.52</td>\n",
       "      <td>403.5</td>\n",
       "      <td>0.09261</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.11120</td>\n",
       "      <td>0.04105</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>...</td>\n",
       "      <td>37.16</td>\n",
       "      <td>82.28</td>\n",
       "      <td>474.2</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.25170</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>0.09653</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.08732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>925292</td>\n",
       "      <td>14.05</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.04462</td>\n",
       "      <td>0.04304</td>\n",
       "      <td>0.1537</td>\n",
       "      <td>...</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.12410</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>925311</td>\n",
       "      <td>11.20</td>\n",
       "      <td>29.37</td>\n",
       "      <td>70.67</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.07449</td>\n",
       "      <td>0.03558</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>...</td>\n",
       "      <td>38.30</td>\n",
       "      <td>75.19</td>\n",
       "      <td>439.6</td>\n",
       "      <td>0.09267</td>\n",
       "      <td>0.05494</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.05905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>925622</td>\n",
       "      <td>15.22</td>\n",
       "      <td>30.62</td>\n",
       "      <td>103.40</td>\n",
       "      <td>716.9</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.09429</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>...</td>\n",
       "      <td>42.79</td>\n",
       "      <td>128.70</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.79170</td>\n",
       "      <td>1.1700</td>\n",
       "      <td>0.23560</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>0.14090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>926125</td>\n",
       "      <td>20.92</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.31740</td>\n",
       "      <td>0.14740</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>...</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.41860</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID NUMBER  rv_IF1  rv_IF2  rv_IF3  rv_IF4   rv_IF5   rv_IF6   rv_IF7  \\\n",
       "559     925291   11.51   23.93   74.52   403.5  0.09261  0.10210  0.11120   \n",
       "560     925292   14.05   27.15   91.38   600.4  0.09929  0.11260  0.04462   \n",
       "561     925311   11.20   29.37   70.67   386.0  0.07449  0.03558  0.00000   \n",
       "562     925622   15.22   30.62  103.40   716.9  0.10480  0.20870  0.25500   \n",
       "563     926125   20.92   25.09  143.00  1347.0  0.10990  0.22360  0.31740   \n",
       "564     926424   21.56   22.39  142.00  1479.0  0.11100  0.11590  0.24390   \n",
       "565     926682   20.13   28.25  131.20  1261.0  0.09780  0.10340  0.14400   \n",
       "566     926954   16.60   28.08  108.30   858.1  0.08455  0.10230  0.09251   \n",
       "567     927241   20.60   29.33  140.10  1265.0  0.11780  0.27700  0.35140   \n",
       "568      92751    7.76   24.54   47.92   181.0  0.05263  0.04362  0.00000   \n",
       "\n",
       "      rv_IF8  rv_IF9  ...  rv_IF22  rv_IF23  rv_IF24  rv_IF25  rv_IF26  \\\n",
       "559  0.04105  0.1388  ...    37.16    82.28    474.2  0.12980  0.25170   \n",
       "560  0.04304  0.1537  ...    33.17   100.20    706.7  0.12410  0.22640   \n",
       "561  0.00000  0.1060  ...    38.30    75.19    439.6  0.09267  0.05494   \n",
       "562  0.09429  0.2128  ...    42.79   128.70    915.0  0.14170  0.79170   \n",
       "563  0.14740  0.2149  ...    29.41   179.10   1819.0  0.14070  0.41860   \n",
       "564  0.13890  0.1726  ...    26.40   166.10   2027.0  0.14100  0.21130   \n",
       "565  0.09791  0.1752  ...    38.25   155.00   1731.0  0.11660  0.19220   \n",
       "566  0.05302  0.1590  ...    34.12   126.70   1124.0  0.11390  0.30940   \n",
       "567  0.15200  0.2397  ...    39.42   184.60   1821.0  0.16500  0.86810   \n",
       "568  0.00000  0.1587  ...    30.37    59.16    268.6  0.08996  0.06444   \n",
       "\n",
       "     rv_IF27  rv_IF28  rv_IF29  rv_IF30  NEW_CLASS  \n",
       "559   0.3630  0.09653   0.2112  0.08732          0  \n",
       "560   0.1326  0.10480   0.2250  0.08321          0  \n",
       "561   0.0000  0.00000   0.1566  0.05905          0  \n",
       "562   1.1700  0.23560   0.4089  0.14090          1  \n",
       "563   0.6599  0.25420   0.2929  0.09873          1  \n",
       "564   0.4107  0.22160   0.2060  0.07115          1  \n",
       "565   0.3215  0.16280   0.2572  0.06637          1  \n",
       "566   0.3403  0.14180   0.2218  0.07820          1  \n",
       "567   0.9387  0.26500   0.4087  0.12400          1  \n",
       "568   0.0000  0.00000   0.2871  0.07039          0  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_enc = LabelEncoder()\n",
    "raw_data[\"NEW_CLASS\"] = lb_enc.fit_transform(raw_data[\"CLASS\"])\n",
    "raw_data[[\"CLASS\", \"NEW_CLASS\"]]\n",
    "df = raw_data.drop(['CLASS'], axis = 1)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09gVn8FPHcTj"
   },
   "outputs": [],
   "source": [
    "data_X = df.drop(['NEW_CLASS'], axis=1)\n",
    "data_y = pd.DataFrame(df['NEW_CLASS'])\n",
    "y = data_y.loc[:,:].values\n",
    "X = data_X.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7230,
     "status": "ok",
     "timestamp": 1564883043581,
     "user": {
      "displayName": "Shanto Paul",
      "photoUrl": "https://lh5.googleusercontent.com/-S7KXSa0Wfc8/AAAAAAAAAAI/AAAAAAAAAbA/psQRjrN7I7w/s64/photo.jpg",
      "userId": "14781007155831330088"
     },
     "user_tz": 240
    },
    "id": "tHo-fVM2t38X",
    "outputId": "4a2fdc16-0a27-4dbd-ddbb-767bb5424c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 31)\n",
      "(114, 31)\n",
      "(455, 1)\n",
      "(114, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V-FVD86rHcTt"
   },
   "source": [
    "### Classification using RBF ANN (entire dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29048,
     "status": "ok",
     "timestamp": 1564883065406,
     "user": {
      "displayName": "Shanto Paul",
      "photoUrl": "https://lh5.googleusercontent.com/-S7KXSa0Wfc8/AAAAAAAAAAI/AAAAAAAAAbA/psQRjrN7I7w/s64/photo.jpg",
      "userId": "14781007155831330088"
     },
     "user_tz": 240
    },
    "id": "bJaLIVCBHcTt",
    "outputId": "8300c02e-0105-4d72-8bbf-c0d1863272ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi ke 0\n",
      "iterasi ke 1\n",
      "iterasi ke 2\n",
      "iterasi ke 3\n",
      "iterasi ke 4\n",
      "iterasi ke 5\n",
      "iterasi ke 6\n",
      "iterasi ke 7\n",
      "iterasi ke 8\n",
      "iterasi ke 9\n",
      "iterasi ke 10\n",
      "iterasi ke 11\n",
      "iterasi ke 12\n",
      "iterasi ke 13\n",
      "iterasi ke 14\n",
      "iterasi ke 15\n",
      "iterasi ke 16\n",
      "iterasi ke 17\n",
      "iterasi ke 18\n",
      "iterasi ke 19\n",
      "iterasi ke 20\n",
      "iterasi ke 21\n",
      "iterasi ke 22\n",
      "iterasi ke 23\n",
      "iterasi ke 24\n",
      "iterasi ke 25\n",
      "iterasi ke 26\n",
      "iterasi ke 27\n",
      "iterasi ke 28\n",
      "iterasi ke 29\n",
      "iterasi ke 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0803 22:29:53.347345 4709258688 deprecation_wrapper.py:119] From /Users/mokul791/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi ke 31\n",
      "iterasi ke 32\n",
      "iterasi ke 33\n",
      "iterasi ke 34\n",
      "iterasi ke 35\n",
      "iterasi ke 36\n",
      "iterasi ke 37\n",
      "iterasi ke 38\n",
      "iterasi ke 39\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0803 22:29:53.397186 4709258688 deprecation_wrapper.py:119] From /Users/mokul791/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0803 22:29:53.431375 4709258688 deprecation_wrapper.py:119] From /Users/mokul791/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0803 22:29:53.463964 4709258688 deprecation_wrapper.py:119] From /Users/mokul791/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0803 22:29:53.494927 4709258688 deprecation_wrapper.py:119] From /Users/mokul791/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0803 22:29:53.501799 4709258688 deprecation.py:323] From /Users/mokul791/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0803 22:29:53.735941 4709258688 deprecation_wrapper.py:119] From /Users/mokul791/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "455/455 [==============================] - 0s 823us/step - loss: 0.7261 - acc: 0.1077\n",
      "Epoch 2/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.7221 - acc: 0.1275\n",
      "Epoch 3/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.7182 - acc: 0.1758\n",
      "Epoch 4/300\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.7146 - acc: 0.2813\n",
      "Epoch 5/300\n",
      "455/455 [==============================] - 0s 172us/step - loss: 0.7109 - acc: 0.3692\n",
      "Epoch 6/300\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.7076 - acc: 0.4681\n",
      "Epoch 7/300\n",
      "455/455 [==============================] - 0s 77us/step - loss: 0.7043 - acc: 0.5473\n",
      "Epoch 8/300\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.7012 - acc: 0.5736\n",
      "Epoch 9/300\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.6983 - acc: 0.6066\n",
      "Epoch 10/300\n",
      "455/455 [==============================] - 0s 73us/step - loss: 0.6954 - acc: 0.6220\n",
      "Epoch 11/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.6927 - acc: 0.6286\n",
      "Epoch 12/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.6901 - acc: 0.6308\n",
      "Epoch 13/300\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.6876 - acc: 0.6308\n",
      "Epoch 14/300\n",
      "455/455 [==============================] - 0s 73us/step - loss: 0.6853 - acc: 0.6308\n",
      "Epoch 15/300\n",
      "455/455 [==============================] - 0s 63us/step - loss: 0.6829 - acc: 0.6286\n",
      "Epoch 16/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.6807 - acc: 0.6286\n",
      "Epoch 17/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.6785 - acc: 0.6286\n",
      "Epoch 18/300\n",
      "455/455 [==============================] - 0s 78us/step - loss: 0.6766 - acc: 0.6286\n",
      "Epoch 19/300\n",
      "455/455 [==============================] - 0s 61us/step - loss: 0.6745 - acc: 0.6286\n",
      "Epoch 20/300\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.6726 - acc: 0.6286\n",
      "Epoch 21/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.6707 - acc: 0.6286\n",
      "Epoch 22/300\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.6689 - acc: 0.6286\n",
      "Epoch 23/300\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.6671 - acc: 0.6286\n",
      "Epoch 24/300\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.6656 - acc: 0.6286\n",
      "Epoch 25/300\n",
      "455/455 [==============================] - 0s 81us/step - loss: 0.6638 - acc: 0.6286\n",
      "Epoch 26/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.6622 - acc: 0.6286\n",
      "Epoch 27/300\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.6607 - acc: 0.6286\n",
      "Epoch 28/300\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.6592 - acc: 0.6286\n",
      "Epoch 29/300\n",
      "455/455 [==============================] - 0s 65us/step - loss: 0.6577 - acc: 0.6286\n",
      "Epoch 30/300\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.6563 - acc: 0.6286\n",
      "Epoch 31/300\n",
      "455/455 [==============================] - 0s 78us/step - loss: 0.6549 - acc: 0.6286\n",
      "Epoch 32/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.6535 - acc: 0.6286\n",
      "Epoch 33/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.6521 - acc: 0.6286\n",
      "Epoch 34/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.6508 - acc: 0.6286\n",
      "Epoch 35/300\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.6495 - acc: 0.6286\n",
      "Epoch 36/300\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.6482 - acc: 0.6286\n",
      "Epoch 37/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.6470 - acc: 0.6286\n",
      "Epoch 38/300\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.6458 - acc: 0.6286\n",
      "Epoch 39/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.6445 - acc: 0.6286\n",
      "Epoch 40/300\n",
      "455/455 [==============================] - 0s 73us/step - loss: 0.6433 - acc: 0.6286\n",
      "Epoch 41/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.6421 - acc: 0.6286\n",
      "Epoch 42/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.6409 - acc: 0.6286\n",
      "Epoch 43/300\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.6398 - acc: 0.6286\n",
      "Epoch 44/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.6386 - acc: 0.6286\n",
      "Epoch 45/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.6375 - acc: 0.6286\n",
      "Epoch 46/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.6363 - acc: 0.6286\n",
      "Epoch 47/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.6352 - acc: 0.6286\n",
      "Epoch 48/300\n",
      "455/455 [==============================] - 0s 73us/step - loss: 0.6341 - acc: 0.6286\n",
      "Epoch 49/300\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.6330 - acc: 0.6286\n",
      "Epoch 50/300\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.6319 - acc: 0.6286\n",
      "Epoch 51/300\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.6308 - acc: 0.6286\n",
      "Epoch 52/300\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.6298 - acc: 0.6286\n",
      "Epoch 53/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.6287 - acc: 0.6286\n",
      "Epoch 54/300\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.6276 - acc: 0.6286\n",
      "Epoch 55/300\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.6266 - acc: 0.6286\n",
      "Epoch 56/300\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.6255 - acc: 0.6286\n",
      "Epoch 57/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.6244 - acc: 0.6286\n",
      "Epoch 58/300\n",
      "455/455 [==============================] - 0s 78us/step - loss: 0.6234 - acc: 0.6286\n",
      "Epoch 59/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.6224 - acc: 0.6286\n",
      "Epoch 60/300\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.6213 - acc: 0.6286\n",
      "Epoch 61/300\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.6203 - acc: 0.6286\n",
      "Epoch 62/300\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.6192 - acc: 0.6308\n",
      "Epoch 63/300\n",
      "455/455 [==============================] - 0s 77us/step - loss: 0.6182 - acc: 0.6308\n",
      "Epoch 64/300\n",
      "455/455 [==============================] - 0s 78us/step - loss: 0.6172 - acc: 0.6308\n",
      "Epoch 65/300\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.6161 - acc: 0.6308\n",
      "Epoch 66/300\n",
      "455/455 [==============================] - 0s 77us/step - loss: 0.6151 - acc: 0.6308\n",
      "Epoch 67/300\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.6141 - acc: 0.6308\n",
      "Epoch 68/300\n",
      "455/455 [==============================] - 0s 80us/step - loss: 0.6131 - acc: 0.6308\n",
      "Epoch 69/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.6121 - acc: 0.6308\n",
      "Epoch 70/300\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.6111 - acc: 0.6308\n",
      "Epoch 71/300\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.6101 - acc: 0.6308\n",
      "Epoch 72/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.6090 - acc: 0.6308\n",
      "Epoch 73/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.6080 - acc: 0.6308\n",
      "Epoch 74/300\n",
      "455/455 [==============================] - 0s 62us/step - loss: 0.6071 - acc: 0.6308\n",
      "Epoch 75/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.6061 - acc: 0.6308\n",
      "Epoch 76/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.6051 - acc: 0.6308\n",
      "Epoch 77/300\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.6041 - acc: 0.6308\n",
      "Epoch 78/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.6030 - acc: 0.6308\n",
      "Epoch 79/300\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.6021 - acc: 0.6308\n",
      "Epoch 80/300\n",
      "455/455 [==============================] - 0s 73us/step - loss: 0.6011 - acc: 0.6308\n",
      "Epoch 81/300\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.6001 - acc: 0.6308\n",
      "Epoch 82/300\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.5991 - acc: 0.6308\n",
      "Epoch 83/300\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.5982 - acc: 0.6308\n",
      "Epoch 84/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 121us/step - loss: 0.5972 - acc: 0.6308\n",
      "Epoch 85/300\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.5962 - acc: 0.6308\n",
      "Epoch 86/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.5952 - acc: 0.6308\n",
      "Epoch 87/300\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.5943 - acc: 0.6308\n",
      "Epoch 88/300\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.5933 - acc: 0.6308\n",
      "Epoch 89/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.5923 - acc: 0.6308\n",
      "Epoch 90/300\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.5914 - acc: 0.6308\n",
      "Epoch 91/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.5904 - acc: 0.6308\n",
      "Epoch 92/300\n",
      "455/455 [==============================] - 0s 63us/step - loss: 0.5894 - acc: 0.6308\n",
      "Epoch 93/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.5885 - acc: 0.6308\n",
      "Epoch 94/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.5875 - acc: 0.6330\n",
      "Epoch 95/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.5866 - acc: 0.6330\n",
      "Epoch 96/300\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.5856 - acc: 0.6330\n",
      "Epoch 97/300\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.5847 - acc: 0.6330\n",
      "Epoch 98/300\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.5837 - acc: 0.6330\n",
      "Epoch 99/300\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.5828 - acc: 0.6330\n",
      "Epoch 100/300\n",
      "455/455 [==============================] - 0s 80us/step - loss: 0.5818 - acc: 0.6330\n",
      "Epoch 101/300\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.5809 - acc: 0.6330\n",
      "Epoch 102/300\n",
      "455/455 [==============================] - 0s 65us/step - loss: 0.5800 - acc: 0.6330\n",
      "Epoch 103/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.5790 - acc: 0.6330\n",
      "Epoch 104/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.5781 - acc: 0.6330\n",
      "Epoch 105/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.5771 - acc: 0.6330\n",
      "Epoch 106/300\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.5762 - acc: 0.6330\n",
      "Epoch 107/300\n",
      "455/455 [==============================] - 0s 80us/step - loss: 0.5753 - acc: 0.6330\n",
      "Epoch 108/300\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.5744 - acc: 0.6330\n",
      "Epoch 109/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.5734 - acc: 0.6352\n",
      "Epoch 110/300\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.5726 - acc: 0.6352\n",
      "Epoch 111/300\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.5716 - acc: 0.6352\n",
      "Epoch 112/300\n",
      "455/455 [==============================] - 0s 139us/step - loss: 0.5707 - acc: 0.6352\n",
      "Epoch 113/300\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.5698 - acc: 0.6352\n",
      "Epoch 114/300\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.5689 - acc: 0.6352\n",
      "Epoch 115/300\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.5679 - acc: 0.6352\n",
      "Epoch 116/300\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.5671 - acc: 0.6352\n",
      "Epoch 117/300\n",
      "455/455 [==============================] - 0s 81us/step - loss: 0.5661 - acc: 0.6352\n",
      "Epoch 118/300\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.5652 - acc: 0.6352\n",
      "Epoch 119/300\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.5643 - acc: 0.6352\n",
      "Epoch 120/300\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.5634 - acc: 0.6374\n",
      "Epoch 121/300\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.5625 - acc: 0.6374\n",
      "Epoch 122/300\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.5616 - acc: 0.6396\n",
      "Epoch 123/300\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.5607 - acc: 0.6440\n",
      "Epoch 124/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.5598 - acc: 0.6440\n",
      "Epoch 125/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.5590 - acc: 0.6462\n",
      "Epoch 126/300\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.5581 - acc: 0.6484\n",
      "Epoch 127/300\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.5572 - acc: 0.6505\n",
      "Epoch 128/300\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.5563 - acc: 0.6527\n",
      "Epoch 129/300\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.5554 - acc: 0.6549\n",
      "Epoch 130/300\n",
      "455/455 [==============================] - 0s 356us/step - loss: 0.5545 - acc: 0.6549\n",
      "Epoch 131/300\n",
      "455/455 [==============================] - 0s 414us/step - loss: 0.5537 - acc: 0.6549\n",
      "Epoch 132/300\n",
      "455/455 [==============================] - 0s 355us/step - loss: 0.5528 - acc: 0.6549\n",
      "Epoch 133/300\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.5519 - acc: 0.6549\n",
      "Epoch 134/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.5511 - acc: 0.6571\n",
      "Epoch 135/300\n",
      "455/455 [==============================] - 0s 131us/step - loss: 0.5502 - acc: 0.6615\n",
      "Epoch 136/300\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.5493 - acc: 0.6615\n",
      "Epoch 137/300\n",
      "455/455 [==============================] - 0s 81us/step - loss: 0.5485 - acc: 0.6637\n",
      "Epoch 138/300\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.5476 - acc: 0.6637\n",
      "Epoch 139/300\n",
      "455/455 [==============================] - 0s 63us/step - loss: 0.5467 - acc: 0.6659\n",
      "Epoch 140/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.5459 - acc: 0.6681\n",
      "Epoch 141/300\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.5450 - acc: 0.6681\n",
      "Epoch 142/300\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.5442 - acc: 0.6681\n",
      "Epoch 143/300\n",
      "455/455 [==============================] - 0s 78us/step - loss: 0.5434 - acc: 0.6747\n",
      "Epoch 144/300\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.5425 - acc: 0.6747\n",
      "Epoch 145/300\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.5416 - acc: 0.6747\n",
      "Epoch 146/300\n",
      "455/455 [==============================] - 0s 80us/step - loss: 0.5408 - acc: 0.6747\n",
      "Epoch 147/300\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.5399 - acc: 0.6747\n",
      "Epoch 148/300\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.5391 - acc: 0.6769\n",
      "Epoch 149/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.5382 - acc: 0.6791\n",
      "Epoch 150/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.5374 - acc: 0.6835\n",
      "Epoch 151/300\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.5366 - acc: 0.6879\n",
      "Epoch 152/300\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.5357 - acc: 0.6879\n",
      "Epoch 153/300\n",
      "455/455 [==============================] - 0s 129us/step - loss: 0.5350 - acc: 0.6879\n",
      "Epoch 154/300\n",
      "455/455 [==============================] - 0s 375us/step - loss: 0.5341 - acc: 0.6879\n",
      "Epoch 155/300\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.5333 - acc: 0.6879\n",
      "Epoch 156/300\n",
      "455/455 [==============================] - 0s 223us/step - loss: 0.5324 - acc: 0.6945\n",
      "Epoch 157/300\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.5316 - acc: 0.6989\n",
      "Epoch 158/300\n",
      "455/455 [==============================] - 0s 285us/step - loss: 0.5308 - acc: 0.6989\n",
      "Epoch 159/300\n",
      "455/455 [==============================] - 0s 196us/step - loss: 0.5300 - acc: 0.7011\n",
      "Epoch 160/300\n",
      "455/455 [==============================] - 0s 175us/step - loss: 0.5292 - acc: 0.7011\n",
      "Epoch 161/300\n",
      "455/455 [==============================] - 0s 222us/step - loss: 0.5283 - acc: 0.7033\n",
      "Epoch 162/300\n",
      "455/455 [==============================] - 0s 191us/step - loss: 0.5275 - acc: 0.7077\n",
      "Epoch 163/300\n",
      "455/455 [==============================] - 0s 148us/step - loss: 0.5267 - acc: 0.7121\n",
      "Epoch 164/300\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.5259 - acc: 0.7143\n",
      "Epoch 165/300\n",
      "455/455 [==============================] - 0s 81us/step - loss: 0.5251 - acc: 0.7165\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 94us/step - loss: 0.5243 - acc: 0.7165\n",
      "Epoch 167/300\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.5236 - acc: 0.7187\n",
      "Epoch 168/300\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.5227 - acc: 0.7231\n",
      "Epoch 169/300\n",
      "455/455 [==============================] - 0s 81us/step - loss: 0.5219 - acc: 0.7253\n",
      "Epoch 170/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.5211 - acc: 0.7275\n",
      "Epoch 171/300\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.5203 - acc: 0.7297\n",
      "Epoch 172/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.5196 - acc: 0.7319\n",
      "Epoch 173/300\n",
      "455/455 [==============================] - 0s 77us/step - loss: 0.5187 - acc: 0.7319\n",
      "Epoch 174/300\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.5180 - acc: 0.7385\n",
      "Epoch 175/300\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.5172 - acc: 0.7429\n",
      "Epoch 176/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.5164 - acc: 0.7429\n",
      "Epoch 177/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.5156 - acc: 0.7451\n",
      "Epoch 178/300\n",
      "455/455 [==============================] - 0s 77us/step - loss: 0.5148 - acc: 0.7451\n",
      "Epoch 179/300\n",
      "455/455 [==============================] - 0s 80us/step - loss: 0.5140 - acc: 0.7451\n",
      "Epoch 180/300\n",
      "455/455 [==============================] - 0s 80us/step - loss: 0.5133 - acc: 0.7495\n",
      "Epoch 181/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.5125 - acc: 0.7516\n",
      "Epoch 182/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.5117 - acc: 0.7516\n",
      "Epoch 183/300\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.5110 - acc: 0.7538\n",
      "Epoch 184/300\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.5102 - acc: 0.7538\n",
      "Epoch 185/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.5094 - acc: 0.7560\n",
      "Epoch 186/300\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.5087 - acc: 0.7560\n",
      "Epoch 187/300\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.5079 - acc: 0.7560\n",
      "Epoch 188/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.5071 - acc: 0.7560\n",
      "Epoch 189/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.5064 - acc: 0.7560\n",
      "Epoch 190/300\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.5056 - acc: 0.7604\n",
      "Epoch 191/300\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.5049 - acc: 0.7604\n",
      "Epoch 192/300\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.5041 - acc: 0.7626\n",
      "Epoch 193/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.5033 - acc: 0.7670\n",
      "Epoch 194/300\n",
      "455/455 [==============================] - 0s 73us/step - loss: 0.5026 - acc: 0.7692\n",
      "Epoch 195/300\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.5019 - acc: 0.7714\n",
      "Epoch 196/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.5011 - acc: 0.7714\n",
      "Epoch 197/300\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.5004 - acc: 0.7714\n",
      "Epoch 198/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.4996 - acc: 0.7714\n",
      "Epoch 199/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.4989 - acc: 0.7736\n",
      "Epoch 200/300\n",
      "455/455 [==============================] - 0s 65us/step - loss: 0.4982 - acc: 0.7802\n",
      "Epoch 201/300\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.4974 - acc: 0.7780\n",
      "Epoch 202/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.4967 - acc: 0.7802\n",
      "Epoch 203/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.4960 - acc: 0.7824\n",
      "Epoch 204/300\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.4952 - acc: 0.7824\n",
      "Epoch 205/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.4945 - acc: 0.7824\n",
      "Epoch 206/300\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.4938 - acc: 0.7868\n",
      "Epoch 207/300\n",
      "455/455 [==============================] - 0s 65us/step - loss: 0.4931 - acc: 0.7912\n",
      "Epoch 208/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.4923 - acc: 0.7934\n",
      "Epoch 209/300\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.4916 - acc: 0.7934\n",
      "Epoch 210/300\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.4909 - acc: 0.7934\n",
      "Epoch 211/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.4902 - acc: 0.7956\n",
      "Epoch 212/300\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.4895 - acc: 0.8000\n",
      "Epoch 213/300\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.4888 - acc: 0.8000\n",
      "Epoch 214/300\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.4880 - acc: 0.8000\n",
      "Epoch 215/300\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.4873 - acc: 0.8022\n",
      "Epoch 216/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.4866 - acc: 0.8022\n",
      "Epoch 217/300\n",
      "455/455 [==============================] - 0s 81us/step - loss: 0.4859 - acc: 0.8022\n",
      "Epoch 218/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.4852 - acc: 0.8044\n",
      "Epoch 219/300\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.4845 - acc: 0.8044\n",
      "Epoch 220/300\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.4838 - acc: 0.8044\n",
      "Epoch 221/300\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.4831 - acc: 0.8044\n",
      "Epoch 222/300\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.4825 - acc: 0.8044\n",
      "Epoch 223/300\n",
      "455/455 [==============================] - 0s 80us/step - loss: 0.4817 - acc: 0.8044\n",
      "Epoch 224/300\n",
      "455/455 [==============================] - 0s 77us/step - loss: 0.4810 - acc: 0.8044\n",
      "Epoch 225/300\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.4804 - acc: 0.8044\n",
      "Epoch 226/300\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.4797 - acc: 0.8066\n",
      "Epoch 227/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.4789 - acc: 0.8066\n",
      "Epoch 228/300\n",
      "455/455 [==============================] - 0s 62us/step - loss: 0.4783 - acc: 0.8066\n",
      "Epoch 229/300\n",
      "455/455 [==============================] - 0s 62us/step - loss: 0.4776 - acc: 0.8066\n",
      "Epoch 230/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.4769 - acc: 0.8088\n",
      "Epoch 231/300\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.4762 - acc: 0.8088\n",
      "Epoch 232/300\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.4756 - acc: 0.8088\n",
      "Epoch 233/300\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.4749 - acc: 0.8132\n",
      "Epoch 234/300\n",
      "455/455 [==============================] - 0s 402us/step - loss: 0.4742 - acc: 0.8132\n",
      "Epoch 235/300\n",
      "455/455 [==============================] - 0s 245us/step - loss: 0.4735 - acc: 0.8154\n",
      "Epoch 236/300\n",
      "455/455 [==============================] - 0s 261us/step - loss: 0.4729 - acc: 0.8176\n",
      "Epoch 237/300\n",
      "455/455 [==============================] - 0s 180us/step - loss: 0.4722 - acc: 0.8154\n",
      "Epoch 238/300\n",
      "455/455 [==============================] - 0s 227us/step - loss: 0.4715 - acc: 0.8176\n",
      "Epoch 239/300\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.4708 - acc: 0.8176\n",
      "Epoch 240/300\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.4702 - acc: 0.8242\n",
      "Epoch 241/300\n",
      "455/455 [==============================] - 0s 166us/step - loss: 0.4695 - acc: 0.8242\n",
      "Epoch 242/300\n",
      "455/455 [==============================] - 0s 121us/step - loss: 0.4689 - acc: 0.8242\n",
      "Epoch 243/300\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.4682 - acc: 0.8242\n",
      "Epoch 244/300\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.4676 - acc: 0.8264\n",
      "Epoch 245/300\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.4669 - acc: 0.8264\n",
      "Epoch 246/300\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.4662 - acc: 0.8286\n",
      "Epoch 247/300\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.4656 - acc: 0.8264\n",
      "Epoch 248/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 111us/step - loss: 0.4650 - acc: 0.8286\n",
      "Epoch 249/300\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.4643 - acc: 0.8286\n",
      "Epoch 250/300\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.4637 - acc: 0.8308\n",
      "Epoch 251/300\n",
      "455/455 [==============================] - 0s 278us/step - loss: 0.4630 - acc: 0.8308\n",
      "Epoch 252/300\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.4624 - acc: 0.8330\n",
      "Epoch 253/300\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.4617 - acc: 0.8352\n",
      "Epoch 254/300\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.4611 - acc: 0.8352\n",
      "Epoch 255/300\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.4605 - acc: 0.8374\n",
      "Epoch 256/300\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.4598 - acc: 0.8374\n",
      "Epoch 257/300\n",
      "455/455 [==============================] - 0s 185us/step - loss: 0.4592 - acc: 0.8352\n",
      "Epoch 258/300\n",
      "455/455 [==============================] - 0s 175us/step - loss: 0.4586 - acc: 0.8374\n",
      "Epoch 259/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.4579 - acc: 0.8396\n",
      "Epoch 260/300\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.4573 - acc: 0.8396\n",
      "Epoch 261/300\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.4567 - acc: 0.8440\n",
      "Epoch 262/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.4561 - acc: 0.8462\n",
      "Epoch 263/300\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.4554 - acc: 0.8484\n",
      "Epoch 264/300\n",
      "455/455 [==============================] - 0s 289us/step - loss: 0.4548 - acc: 0.8505\n",
      "Epoch 265/300\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.4542 - acc: 0.8505\n",
      "Epoch 266/300\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.4536 - acc: 0.8505\n",
      "Epoch 267/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.4529 - acc: 0.8505\n",
      "Epoch 268/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.4523 - acc: 0.8505\n",
      "Epoch 269/300\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.4517 - acc: 0.8505\n",
      "Epoch 270/300\n",
      "455/455 [==============================] - 0s 176us/step - loss: 0.4511 - acc: 0.8505\n",
      "Epoch 271/300\n",
      "455/455 [==============================] - 0s 77us/step - loss: 0.4505 - acc: 0.8527\n",
      "Epoch 272/300\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.4499 - acc: 0.8527\n",
      "Epoch 273/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.4493 - acc: 0.8571\n",
      "Epoch 274/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.4487 - acc: 0.8571\n",
      "Epoch 275/300\n",
      "455/455 [==============================] - 0s 65us/step - loss: 0.4481 - acc: 0.8571\n",
      "Epoch 276/300\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.4475 - acc: 0.8571\n",
      "Epoch 277/300\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.4468 - acc: 0.8571\n",
      "Epoch 278/300\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.4463 - acc: 0.8593\n",
      "Epoch 279/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.4456 - acc: 0.8615\n",
      "Epoch 280/300\n",
      "455/455 [==============================] - 0s 73us/step - loss: 0.4451 - acc: 0.8615\n",
      "Epoch 281/300\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.4445 - acc: 0.8615\n",
      "Epoch 282/300\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.4439 - acc: 0.8615\n",
      "Epoch 283/300\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.4433 - acc: 0.8637\n",
      "Epoch 284/300\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.4427 - acc: 0.8637\n",
      "Epoch 285/300\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.4421 - acc: 0.8637\n",
      "Epoch 286/300\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.4415 - acc: 0.8637\n",
      "Epoch 287/300\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.4409 - acc: 0.8659\n",
      "Epoch 288/300\n",
      "455/455 [==============================] - 0s 77us/step - loss: 0.4403 - acc: 0.8659\n",
      "Epoch 289/300\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.4398 - acc: 0.8703\n",
      "Epoch 290/300\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.4392 - acc: 0.8703\n",
      "Epoch 291/300\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.4386 - acc: 0.8703\n",
      "Epoch 292/300\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.4380 - acc: 0.8703\n",
      "Epoch 293/300\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.4375 - acc: 0.8725\n",
      "Epoch 294/300\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.4369 - acc: 0.8747\n",
      "Epoch 295/300\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.4363 - acc: 0.8747\n",
      "Epoch 296/300\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.4357 - acc: 0.8747\n",
      "Epoch 297/300\n",
      "455/455 [==============================] - 0s 63us/step - loss: 0.4352 - acc: 0.8747\n",
      "Epoch 298/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.4346 - acc: 0.8747\n",
      "Epoch 299/300\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.4341 - acc: 0.8703\n",
      "Epoch 300/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.4335 - acc: 0.8703\n",
      "[0.24301636] [0]\n",
      "[0.400797] [0]\n",
      "[0.43597907] [0]\n",
      "[0.25731072] [0]\n",
      "[0.32521635] [0]\n",
      "[0.5650903] [1]\n",
      "[0.20205984] [0]\n",
      "[0.44528398] [0]\n",
      "[0.5127053] [0]\n",
      "[0.31152773] [0]\n",
      "[0.32792947] [0]\n",
      "[0.4936606] [1]\n",
      "[0.6655343] [1]\n",
      "[0.4210938] [0]\n",
      "[0.5043924] [1]\n",
      "[0.35556936] [0]\n",
      "[0.1558195] [0]\n",
      "[0.25970972] [0]\n",
      "[0.21599576] [0]\n",
      "[0.2966904] [0]\n",
      "[0.6002922] [1]\n",
      "[0.5096969] [1]\n",
      "[0.47696728] [1]\n",
      "[0.67516255] [1]\n",
      "[0.5878705] [1]\n",
      "[0.43598685] [0]\n",
      "[0.20358106] [0]\n",
      "[0.1980561] [0]\n",
      "[0.284832] [0]\n",
      "[0.5141292] [1]\n",
      "[0.21065307] [0]\n",
      "[0.5633448] [1]\n",
      "[0.39878258] [0]\n",
      "[0.6332842] [1]\n",
      "[0.08372882] [0]\n",
      "[0.13536167] [0]\n",
      "[0.17677903] [0]\n",
      "[0.32423058] [0]\n",
      "[0.3084419] [0]\n",
      "[0.4798974] [1]\n",
      "[0.5093377] [0]\n",
      "[0.26255298] [0]\n",
      "[0.18040258] [1]\n",
      "[0.6101334] [1]\n",
      "[0.49193645] [0]\n",
      "[0.45066285] [0]\n",
      "[0.27475908] [0]\n",
      "[0.29016364] [0]\n",
      "[0.34421492] [1]\n",
      "[0.3082455] [0]\n",
      "[0.13698018] [0]\n",
      "[0.1092793] [0]\n",
      "[0.1292611] [0]\n",
      "[0.3462165] [0]\n",
      "[0.10010493] [0]\n",
      "[0.4919566] [1]\n",
      "[0.462356] [1]\n",
      "[0.29145116] [1]\n",
      "[0.10169497] [0]\n",
      "[0.24401256] [0]\n",
      "[0.17816657] [0]\n",
      "[0.51445764] [1]\n",
      "[0.33347413] [0]\n",
      "[0.6628241] [1]\n",
      "[0.46741727] [1]\n",
      "[0.3188117] [0]\n",
      "[0.31973392] [0]\n",
      "[0.52033246] [1]\n",
      "[0.5523058] [1]\n",
      "[0.35740405] [0]\n",
      "[0.47857493] [0]\n",
      "[0.13940701] [0]\n",
      "[0.27216956] [0]\n",
      "[0.17358634] [0]\n",
      "[0.14620817] [0]\n",
      "[0.64422977] [1]\n",
      "[0.5429983] [1]\n",
      "[0.46955162] [1]\n",
      "[0.11247176] [0]\n",
      "[0.4681594] [0]\n",
      "[0.09715685] [0]\n",
      "[0.19810286] [0]\n",
      "[0.20168081] [0]\n",
      "[0.16151625] [0]\n",
      "[0.56581074] [1]\n",
      "[0.6734047] [1]\n",
      "[0.53737533] [1]\n",
      "[0.19356361] [0]\n",
      "[0.10687065] [0]\n",
      "[0.5297576] [1]\n",
      "[0.19620964] [0]\n",
      "[0.6301097] [1]\n",
      "[0.628567] [1]\n",
      "[0.23137909] [0]\n",
      "[0.45053512] [0]\n",
      "[0.171756] [0]\n",
      "[0.7682743] [1]\n",
      "[0.54212534] [1]\n",
      "[0.4809531] [0]\n",
      "[0.5663998] [0]\n",
      "[0.662644] [1]\n",
      "[0.35957018] [0]\n",
      "[0.52686024] [1]\n",
      "[0.6734221] [1]\n",
      "[0.20773521] [0]\n",
      "[0.32206187] [0]\n",
      "[0.53265953] [1]\n",
      "[0.5317596] [1]\n",
      "[0.4232619] [1]\n",
      "[0.11600184] [0]\n",
      "[0.35716465] [0]\n",
      "[0.32440668] [0]\n",
      "[0.51760453] [1]\n",
      "[0.13502806] [0]\n",
      "0.8771929824561403 0.13904409127525116\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, LSTM, RepeatVector, TimeDistributed\n",
    "#setting\n",
    "kval = 10\n",
    "itertot = 40\n",
    "sigma = 1.2\n",
    "itergd = 300\n",
    "def transforminput(param, center):\n",
    " newinput = np.zeros((len(param), len(center))).astype('float32')\n",
    " for i in range(len(param)):\n",
    "  for j in range(len(center)):\n",
    "   newinput[i,j] = np.exp(-(np.sum((param[i] - center[j])**2.0)**0.5) / sigma**2.0)\n",
    " return newinput\n",
    "def generatemodel(numparam):\n",
    " model = Sequential()\n",
    " model.add(Dense(1, input_dim=numparam, activation='sigmoid'))\n",
    "# model.add(Dense(10, activation='sigmoid'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    " # Compile model\n",
    " model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " return model\n",
    "#dividing data\n",
    "trainparam = X_train\n",
    "trainlabel = y_train\n",
    "testparam = X_test\n",
    "testlabel = y_test\n",
    "###############\n",
    "#normalization#\n",
    "###############\n",
    "std = np.zeros((len(trainparam[0]))).astype('float32')\n",
    "rata = np.zeros((len(trainparam[0]))).astype('float32')\n",
    "trainparamnorm = np.zeros(np.shape(trainparam))\n",
    "testparamnorm = np.zeros(np.shape(testparam))\n",
    "for i in range(len(trainparam[0])):\n",
    " std[i] = np.std(trainparam[:,i])\n",
    " rata[i] = np.mean(trainparam[:,i])\n",
    " trainparamnorm[:,i] = (trainparam[:,i] - rata[i]) / std[i]\n",
    " testparamnorm[:,i] = (testparam[:,i] - rata[i]) / std[i]\n",
    "###############\n",
    "#search k-mean#\n",
    "###############\n",
    "#init kmean\n",
    "kmean = np.zeros((kval, len(trainparamnorm[0])))\n",
    "for i in range(kval):\n",
    " for j in range(len(kmean[0])):\n",
    "  kmean[i,j] = random.uniform(min(trainparamnorm[:,j]),max(trainparamnorm[:,j]))\n",
    "#looping of real algorithm\n",
    "distmin = np.zeros((len(trainparamnorm)))\n",
    "for i in range(itertot):\n",
    " print ('iterasi ke', i)\n",
    " for j in range(len(distmin)):\n",
    "  #determine euclid distance\n",
    "  distall = np.sum((trainparamnorm[j] - kmean)**2.0, axis=1)**0.5\n",
    "  distmin[j] = np.argmin(distall)\n",
    "#search new k mean\n",
    " for j in range(kval):\n",
    "  clust = []\n",
    "  for k in range(len(distmin)):\n",
    "   if distmin[k] == j:\n",
    "    clust.append(trainparamnorm[k])\n",
    "  if len(clust) > 0:\n",
    "   kmean[j] = np.mean(np.asarray(clust), axis=0)\n",
    "#tranform our input\n",
    "newinput = transforminput(trainparamnorm, kmean)\n",
    "print (trainlabel)\n",
    "##########################\n",
    "#gradient descent session#\n",
    "##########################\n",
    "mod = generatemodel(kval)\n",
    "mod.fit(newinput, trainlabel, batch_size=20, epochs=itergd, verbose=1, shuffle=True)\n",
    "##################\n",
    "#predict session#\n",
    "##################\n",
    "#transform test data\n",
    "newinputtest = transforminput(testparamnorm, kmean)\n",
    "lifeprob = mod.predict(newinputtest)\n",
    "#######################\n",
    "#determine performance#\n",
    "#######################\n",
    "#determine biner accuracy\n",
    "binpred = np.zeros((len(lifeprob)))\n",
    "for i in range(len(lifeprob)):\n",
    " if lifeprob[i] > 0.5:\n",
    "  binpred[i] = 1.\n",
    "score = 0\n",
    "for i in range(len(testlabel)):\n",
    " if binpred[i] == testlabel[i]:\n",
    "  score += 1\n",
    "accbin = float(score) / float(len(testlabel))\n",
    "#determine brier score\n",
    "brierscore = 0\n",
    "for i in range(len(testlabel)):\n",
    " brierscore += (testlabel[i] - lifeprob[i])**2.0\n",
    "brierscore = brierscore / float(len(testlabel))\n",
    "for i in range(len(testlabel)):\n",
    " print (lifeprob[i], testlabel[i])\n",
    "print (accbin, brierscore[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jJh4oaPIHcTv"
   },
   "source": [
    "### Dimentionality reduction using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29051,
     "status": "ok",
     "timestamp": 1564883065412,
     "user": {
      "displayName": "Shanto Paul",
      "photoUrl": "https://lh5.googleusercontent.com/-S7KXSa0Wfc8/AAAAAAAAAAI/AAAAAAAAAbA/psQRjrN7I7w/s64/photo.jpg",
      "userId": "14781007155831330088"
     },
     "user_tz": 240
    },
    "id": "Iy3TgoyFHcTw",
    "outputId": "9015c96d-d84b-404d-984e-3b458c16feef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mokul791/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/mokul791/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/mokul791/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(569, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LDA(n_components = 2)\n",
    "X_lda = lda.fit_transform(X, y) \n",
    "X_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29118,
     "status": "ok",
     "timestamp": 1564883065483,
     "user": {
      "displayName": "Shanto Paul",
      "photoUrl": "https://lh5.googleusercontent.com/-S7KXSa0Wfc8/AAAAAAAAAAI/AAAAAAAAAbA/psQRjrN7I7w/s64/photo.jpg",
      "userId": "14781007155831330088"
     },
     "user_tz": 240
    },
    "id": "nAl_NiRIHcTz",
    "outputId": "2809c0a3-a37f-410e-a459-fa8d6f7c40fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st-component</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>4.558057</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>2.940792</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.984996</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>5.888918</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-2.723290</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1st-component  CLASS\n",
       "564       4.558057    1.0\n",
       "565       2.940792    1.0\n",
       "566       0.984996    1.0\n",
       "567       5.888918    1.0\n",
       "568      -2.723290    0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_data = np.vstack((X_lda.T, df['NEW_CLASS'])).T\n",
    "lda_df   = pd.DataFrame(data=lda_data, columns=(\"1st-component\",\"CLASS\"))\n",
    "lda_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29107,
     "status": "ok",
     "timestamp": 1564883065484,
     "user": {
      "displayName": "Shanto Paul",
      "photoUrl": "https://lh5.googleusercontent.com/-S7KXSa0Wfc8/AAAAAAAAAAI/AAAAAAAAAbA/psQRjrN7I7w/s64/photo.jpg",
      "userId": "14781007155831330088"
     },
     "user_tz": 240
    },
    "id": "w7JHAcKiHcT1",
    "outputId": "47072e3c-b2c0-464c-d3ec-6a103946ada2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 1)\n",
      "(114, 1)\n",
      "(455, 1)\n",
      "(114, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lda, y, test_size=0.2, random_state=0, stratify=y)\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eIVTlcVkHcUC"
   },
   "source": [
    "\n",
    "\n",
    "### Classification using RBF ANN (after LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 51274,
     "status": "ok",
     "timestamp": 1564883087688,
     "user": {
      "displayName": "Shanto Paul",
      "photoUrl": "https://lh5.googleusercontent.com/-S7KXSa0Wfc8/AAAAAAAAAAI/AAAAAAAAAbA/psQRjrN7I7w/s64/photo.jpg",
      "userId": "14781007155831330088"
     },
     "user_tz": 240
    },
    "id": "15XAhOY6HcUD",
    "outputId": "e8649c44-05c9-4e73-e5e3-69b101aa040e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi ke 0\n",
      "iterasi ke 1\n",
      "iterasi ke 2\n",
      "iterasi ke 3\n",
      "iterasi ke 4\n",
      "iterasi ke 5\n",
      "iterasi ke 6\n",
      "iterasi ke 7\n",
      "iterasi ke 8\n",
      "iterasi ke 9\n",
      "iterasi ke 10\n",
      "iterasi ke 11\n",
      "iterasi ke 12\n",
      "iterasi ke 13\n",
      "iterasi ke 14\n",
      "iterasi ke 15\n",
      "iterasi ke 16\n",
      "iterasi ke 17\n",
      "iterasi ke 18\n",
      "iterasi ke 19\n",
      "iterasi ke 20\n",
      "iterasi ke 21\n",
      "iterasi ke 22\n",
      "iterasi ke 23\n",
      "iterasi ke 24\n",
      "iterasi ke 25\n",
      "iterasi ke 26\n",
      "iterasi ke 27\n",
      "iterasi ke 28\n",
      "iterasi ke 29\n",
      "iterasi ke 30\n",
      "iterasi ke 31\n",
      "iterasi ke 32\n",
      "iterasi ke 33\n",
      "iterasi ke 34\n",
      "iterasi ke 35\n",
      "iterasi ke 36\n",
      "iterasi ke 37\n",
      "iterasi ke 38\n",
      "iterasi ke 39\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Epoch 1/300\n",
      "455/455 [==============================] - 0s 567us/step - loss: 0.6298 - acc: 0.6264\n",
      "Epoch 2/300\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.6141 - acc: 0.6264\n",
      "Epoch 3/300\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.5985 - acc: 0.6264\n",
      "Epoch 4/300\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.5839 - acc: 0.6264\n",
      "Epoch 5/300\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.5690 - acc: 0.6308\n",
      "Epoch 6/300\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.5551 - acc: 0.6330\n",
      "Epoch 7/300\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.5417 - acc: 0.6352\n",
      "Epoch 8/300\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.5287 - acc: 0.6418\n",
      "Epoch 9/300\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.5159 - acc: 0.7099\n",
      "Epoch 10/300\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.5036 - acc: 0.7758\n",
      "Epoch 11/300\n",
      "455/455 [==============================] - 0s 77us/step - loss: 0.4920 - acc: 0.7912\n",
      "Epoch 12/300\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.4806 - acc: 0.8198\n",
      "Epoch 13/300\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.4695 - acc: 0.8418\n",
      "Epoch 14/300\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.4592 - acc: 0.8484\n",
      "Epoch 15/300\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.4488 - acc: 0.8527\n",
      "Epoch 16/300\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.4391 - acc: 0.8637\n",
      "Epoch 17/300\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.4295 - acc: 0.8659\n",
      "Epoch 18/300\n",
      "455/455 [==============================] - 0s 73us/step - loss: 0.4202 - acc: 0.8791\n",
      "Epoch 19/300\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.4114 - acc: 0.8813\n",
      "Epoch 20/300\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.4026 - acc: 0.8857\n",
      "Epoch 21/300\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.3944 - acc: 0.8879\n",
      "Epoch 22/300\n",
      "455/455 [==============================] - 0s 77us/step - loss: 0.3861 - acc: 0.8945\n",
      "Epoch 23/300\n",
      "455/455 [==============================] - 0s 425us/step - loss: 0.3783 - acc: 0.8967\n",
      "Epoch 24/300\n",
      "455/455 [==============================] - 0s 428us/step - loss: 0.3706 - acc: 0.8967\n",
      "Epoch 25/300\n",
      "455/455 [==============================] - 0s 308us/step - loss: 0.3634 - acc: 0.8989\n",
      "Epoch 26/300\n",
      "455/455 [==============================] - 0s 317us/step - loss: 0.3562 - acc: 0.9011\n",
      "Epoch 27/300\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.3493 - acc: 0.9055\n",
      "Epoch 28/300\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.3427 - acc: 0.9077\n",
      "Epoch 29/300\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.3362 - acc: 0.9143\n",
      "Epoch 30/300\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.3300 - acc: 0.9165\n",
      "Epoch 31/300\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.3239 - acc: 0.9187\n",
      "Epoch 32/300\n",
      "455/455 [==============================] - 0s 394us/step - loss: 0.3181 - acc: 0.9209\n",
      "Epoch 33/300\n",
      "455/455 [==============================] - 0s 642us/step - loss: 0.3123 - acc: 0.9253\n",
      "Epoch 34/300\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.3069 - acc: 0.9253\n",
      "Epoch 35/300\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.3015 - acc: 0.9275\n",
      "Epoch 36/300\n",
      "455/455 [==============================] - 0s 81us/step - loss: 0.2963 - acc: 0.9297\n",
      "Epoch 37/300\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.2914 - acc: 0.9319\n",
      "Epoch 38/300\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.2865 - acc: 0.9319\n",
      "Epoch 39/300\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.2817 - acc: 0.9341\n",
      "Epoch 40/300\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.2771 - acc: 0.9407\n",
      "Epoch 41/300\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.2727 - acc: 0.9429\n",
      "Epoch 42/300\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.2684 - acc: 0.9429\n",
      "Epoch 43/300\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.2642 - acc: 0.9429\n",
      "Epoch 44/300\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.2601 - acc: 0.9451\n",
      "Epoch 45/300\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.2562 - acc: 0.9451\n",
      "Epoch 46/300\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.2523 - acc: 0.9473\n",
      "Epoch 47/300\n",
      "455/455 [==============================] - 0s 249us/step - loss: 0.2486 - acc: 0.9516\n",
      "Epoch 48/300\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.2450 - acc: 0.9538\n",
      "Epoch 49/300\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.2414 - acc: 0.9538\n",
      "Epoch 50/300\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.2380 - acc: 0.9538\n",
      "Epoch 51/300\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.2347 - acc: 0.9560\n",
      "Epoch 52/300\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.2314 - acc: 0.9560\n",
      "Epoch 53/300\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.2283 - acc: 0.9560\n",
      "Epoch 54/300\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.2252 - acc: 0.9582\n",
      "Epoch 55/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 87us/step - loss: 0.2221 - acc: 0.9582\n",
      "Epoch 56/300\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.2192 - acc: 0.9582\n",
      "Epoch 57/300\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.2164 - acc: 0.9582\n",
      "Epoch 58/300\n",
      "455/455 [==============================] - ETA: 0s - loss: 0.1454 - acc: 1.000 - 0s 95us/step - loss: 0.2136 - acc: 0.9582\n",
      "Epoch 59/300\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.2109 - acc: 0.9582\n",
      "Epoch 60/300\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.2083 - acc: 0.9604\n",
      "Epoch 61/300\n",
      "455/455 [==============================] - 0s 61us/step - loss: 0.2058 - acc: 0.9604\n",
      "Epoch 62/300\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.2032 - acc: 0.9604\n",
      "Epoch 63/300\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.2007 - acc: 0.9604\n",
      "Epoch 64/300\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.1984 - acc: 0.9604\n",
      "Epoch 65/300\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.1960 - acc: 0.9626\n",
      "Epoch 66/300\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.1938 - acc: 0.9626\n",
      "Epoch 67/300\n",
      "455/455 [==============================] - 0s 315us/step - loss: 0.1915 - acc: 0.9626\n",
      "Epoch 68/300\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.1894 - acc: 0.9648\n",
      "Epoch 69/300\n",
      "455/455 [==============================] - 0s 173us/step - loss: 0.1872 - acc: 0.9648\n",
      "Epoch 70/300\n",
      "455/455 [==============================] - 0s 163us/step - loss: 0.1852 - acc: 0.9648\n",
      "Epoch 71/300\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.1832 - acc: 0.9670\n",
      "Epoch 72/300\n",
      "455/455 [==============================] - 0s 117us/step - loss: 0.1812 - acc: 0.9670\n",
      "Epoch 73/300\n",
      "455/455 [==============================] - 0s 236us/step - loss: 0.1793 - acc: 0.9670\n",
      "Epoch 74/300\n",
      "455/455 [==============================] - 0s 193us/step - loss: 0.1774 - acc: 0.9670\n",
      "Epoch 75/300\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.1755 - acc: 0.9670\n",
      "Epoch 76/300\n",
      "455/455 [==============================] - 0s 187us/step - loss: 0.1738 - acc: 0.9670\n",
      "Epoch 77/300\n",
      "455/455 [==============================] - 0s 176us/step - loss: 0.1720 - acc: 0.9670\n",
      "Epoch 78/300\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.1702 - acc: 0.9670\n",
      "Epoch 79/300\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.1685 - acc: 0.9670\n",
      "Epoch 80/300\n",
      "455/455 [==============================] - 0s 422us/step - loss: 0.1669 - acc: 0.9670\n",
      "Epoch 81/300\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.1653 - acc: 0.9670\n",
      "Epoch 82/300\n",
      "455/455 [==============================] - 0s 114us/step - loss: 0.1637 - acc: 0.9670\n",
      "Epoch 83/300\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.1621 - acc: 0.9670\n",
      "Epoch 84/300\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.1607 - acc: 0.9670\n",
      "Epoch 85/300\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.1591 - acc: 0.9670\n",
      "Epoch 86/300\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.1577 - acc: 0.9670\n",
      "Epoch 87/300\n",
      "455/455 [==============================] - 0s 230us/step - loss: 0.1563 - acc: 0.9670\n",
      "Epoch 88/300\n",
      "455/455 [==============================] - 0s 146us/step - loss: 0.1549 - acc: 0.9670\n",
      "Epoch 89/300\n",
      "455/455 [==============================] - 0s 162us/step - loss: 0.1535 - acc: 0.9670\n",
      "Epoch 90/300\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.1522 - acc: 0.9670\n",
      "Epoch 91/300\n",
      "455/455 [==============================] - 0s 164us/step - loss: 0.1509 - acc: 0.9670\n",
      "Epoch 92/300\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.1496 - acc: 0.9670\n",
      "Epoch 93/300\n",
      "455/455 [==============================] - 0s 235us/step - loss: 0.1483 - acc: 0.9692\n",
      "Epoch 94/300\n",
      "455/455 [==============================] - 0s 190us/step - loss: 0.1471 - acc: 0.9692\n",
      "Epoch 95/300\n",
      "455/455 [==============================] - 0s 129us/step - loss: 0.1459 - acc: 0.9692\n",
      "Epoch 96/300\n",
      "455/455 [==============================] - 0s 239us/step - loss: 0.1447 - acc: 0.9692\n",
      "Epoch 97/300\n",
      "455/455 [==============================] - 0s 222us/step - loss: 0.1436 - acc: 0.9692\n",
      "Epoch 98/300\n",
      "455/455 [==============================] - 0s 195us/step - loss: 0.1424 - acc: 0.9692\n",
      "Epoch 99/300\n",
      "455/455 [==============================] - 0s 199us/step - loss: 0.1413 - acc: 0.9692\n",
      "Epoch 100/300\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.1403 - acc: 0.9692\n",
      "Epoch 101/300\n",
      "455/455 [==============================] - 0s 170us/step - loss: 0.1392 - acc: 0.9692\n",
      "Epoch 102/300\n",
      "455/455 [==============================] - 0s 120us/step - loss: 0.1382 - acc: 0.9692\n",
      "Epoch 103/300\n",
      "455/455 [==============================] - 0s 304us/step - loss: 0.1370 - acc: 0.9692\n",
      "Epoch 104/300\n",
      "455/455 [==============================] - 0s 114us/step - loss: 0.1361 - acc: 0.9692\n",
      "Epoch 105/300\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.1351 - acc: 0.9692\n",
      "Epoch 106/300\n",
      "455/455 [==============================] - 0s 114us/step - loss: 0.1341 - acc: 0.9692\n",
      "Epoch 107/300\n",
      "455/455 [==============================] - 0s 174us/step - loss: 0.1332 - acc: 0.9692\n",
      "Epoch 108/300\n",
      "455/455 [==============================] - 0s 187us/step - loss: 0.1323 - acc: 0.9692\n",
      "Epoch 109/300\n",
      "455/455 [==============================] - 0s 180us/step - loss: 0.1313 - acc: 0.9714\n",
      "Epoch 110/300\n",
      "455/455 [==============================] - 0s 119us/step - loss: 0.1304 - acc: 0.9714\n",
      "Epoch 111/300\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.1295 - acc: 0.9714\n",
      "Epoch 112/300\n",
      "455/455 [==============================] - 0s 119us/step - loss: 0.1286 - acc: 0.9714\n",
      "Epoch 113/300\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.1277 - acc: 0.9714\n",
      "Epoch 114/300\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.1269 - acc: 0.9714\n",
      "Epoch 115/300\n",
      "455/455 [==============================] - 0s 172us/step - loss: 0.1261 - acc: 0.9714\n",
      "Epoch 116/300\n",
      "455/455 [==============================] - 0s 151us/step - loss: 0.1252 - acc: 0.9714\n",
      "Epoch 117/300\n",
      "455/455 [==============================] - 0s 139us/step - loss: 0.1244 - acc: 0.9714\n",
      "Epoch 118/300\n",
      "455/455 [==============================] - 0s 223us/step - loss: 0.1237 - acc: 0.9714\n",
      "Epoch 119/300\n",
      "455/455 [==============================] - 0s 217us/step - loss: 0.1229 - acc: 0.9714\n",
      "Epoch 120/300\n",
      "455/455 [==============================] - 0s 148us/step - loss: 0.1221 - acc: 0.9714\n",
      "Epoch 121/300\n",
      "455/455 [==============================] - 0s 205us/step - loss: 0.1213 - acc: 0.9714\n",
      "Epoch 122/300\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.1206 - acc: 0.9714\n",
      "Epoch 123/300\n",
      "455/455 [==============================] - 0s 273us/step - loss: 0.1199 - acc: 0.9714\n",
      "Epoch 124/300\n",
      "455/455 [==============================] - 0s 197us/step - loss: 0.1192 - acc: 0.9714\n",
      "Epoch 125/300\n",
      "455/455 [==============================] - 0s 217us/step - loss: 0.1184 - acc: 0.9714\n",
      "Epoch 126/300\n",
      "455/455 [==============================] - 0s 255us/step - loss: 0.1178 - acc: 0.9714\n",
      "Epoch 127/300\n",
      "455/455 [==============================] - 0s 438us/step - loss: 0.1171 - acc: 0.9714\n",
      "Epoch 128/300\n",
      "455/455 [==============================] - 0s 268us/step - loss: 0.1164 - acc: 0.9714\n",
      "Epoch 129/300\n",
      "455/455 [==============================] - 0s 114us/step - loss: 0.1158 - acc: 0.9714\n",
      "Epoch 130/300\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.1151 - acc: 0.9714\n",
      "Epoch 131/300\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.1145 - acc: 0.9714\n",
      "Epoch 132/300\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.1138 - acc: 0.9714\n",
      "Epoch 133/300\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.1133 - acc: 0.9714\n",
      "Epoch 134/300\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.1126 - acc: 0.9714\n",
      "Epoch 135/300\n",
      "455/455 [==============================] - 0s 230us/step - loss: 0.1120 - acc: 0.9714\n",
      "Epoch 136/300\n",
      "455/455 [==============================] - 0s 241us/step - loss: 0.1114 - acc: 0.9714\n",
      "Epoch 137/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 185us/step - loss: 0.1108 - acc: 0.9714\n",
      "Epoch 138/300\n",
      "455/455 [==============================] - 0s 177us/step - loss: 0.1102 - acc: 0.9714\n",
      "Epoch 139/300\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.1097 - acc: 0.9714\n",
      "Epoch 140/300\n",
      "455/455 [==============================] - 0s 291us/step - loss: 0.1091 - acc: 0.9714\n",
      "Epoch 141/300\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.1086 - acc: 0.9714\n",
      "Epoch 142/300\n",
      "455/455 [==============================] - 0s 275us/step - loss: 0.1081 - acc: 0.9714\n",
      "Epoch 143/300\n",
      "455/455 [==============================] - 0s 212us/step - loss: 0.1076 - acc: 0.9714\n",
      "Epoch 144/300\n",
      "455/455 [==============================] - 0s 153us/step - loss: 0.1071 - acc: 0.9714\n",
      "Epoch 145/300\n",
      "455/455 [==============================] - 0s 188us/step - loss: 0.1065 - acc: 0.9714\n",
      "Epoch 146/300\n",
      "455/455 [==============================] - 0s 178us/step - loss: 0.1061 - acc: 0.9714\n",
      "Epoch 147/300\n",
      "455/455 [==============================] - 0s 189us/step - loss: 0.1055 - acc: 0.9714\n",
      "Epoch 148/300\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.1050 - acc: 0.9714\n",
      "Epoch 149/300\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.1045 - acc: 0.9714\n",
      "Epoch 150/300\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.1041 - acc: 0.9714\n",
      "Epoch 151/300\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.1035 - acc: 0.9714\n",
      "Epoch 152/300\n",
      "455/455 [==============================] - 0s 309us/step - loss: 0.1031 - acc: 0.9714\n",
      "Epoch 153/300\n",
      "455/455 [==============================] - 0s 193us/step - loss: 0.1026 - acc: 0.9714\n",
      "Epoch 154/300\n",
      "455/455 [==============================] - 0s 131us/step - loss: 0.1022 - acc: 0.9714\n",
      "Epoch 155/300\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.1018 - acc: 0.9714\n",
      "Epoch 156/300\n",
      "455/455 [==============================] - 0s 137us/step - loss: 0.1013 - acc: 0.9714\n",
      "Epoch 157/300\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.1009 - acc: 0.9714\n",
      "Epoch 158/300\n",
      "455/455 [==============================] - 0s 179us/step - loss: 0.1005 - acc: 0.9714\n",
      "Epoch 159/300\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.1000 - acc: 0.9736\n",
      "Epoch 160/300\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.0996 - acc: 0.9736\n",
      "Epoch 161/300\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.0992 - acc: 0.9714\n",
      "Epoch 162/300\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.0988 - acc: 0.9736\n",
      "Epoch 163/300\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0984 - acc: 0.9736\n",
      "Epoch 164/300\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0980 - acc: 0.9736\n",
      "Epoch 165/300\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0976 - acc: 0.9736\n",
      "Epoch 166/300\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0972 - acc: 0.9736\n",
      "Epoch 167/300\n",
      "455/455 [==============================] - 0s 284us/step - loss: 0.0969 - acc: 0.9736\n",
      "Epoch 168/300\n",
      "455/455 [==============================] - 0s 189us/step - loss: 0.0965 - acc: 0.9736\n",
      "Epoch 169/300\n",
      "455/455 [==============================] - 0s 160us/step - loss: 0.0961 - acc: 0.9736\n",
      "Epoch 170/300\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.0958 - acc: 0.9736\n",
      "Epoch 171/300\n",
      "455/455 [==============================] - 0s 184us/step - loss: 0.0954 - acc: 0.9736\n",
      "Epoch 172/300\n",
      "455/455 [==============================] - 0s 136us/step - loss: 0.0951 - acc: 0.9736\n",
      "Epoch 173/300\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.0947 - acc: 0.9736\n",
      "Epoch 174/300\n",
      "455/455 [==============================] - 0s 179us/step - loss: 0.0944 - acc: 0.9714\n",
      "Epoch 175/300\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0940 - acc: 0.9714\n",
      "Epoch 176/300\n",
      "455/455 [==============================] - 0s 277us/step - loss: 0.0937 - acc: 0.9736\n",
      "Epoch 177/300\n",
      "455/455 [==============================] - 0s 174us/step - loss: 0.0934 - acc: 0.9714\n",
      "Epoch 178/300\n",
      "455/455 [==============================] - 0s 175us/step - loss: 0.0930 - acc: 0.9736\n",
      "Epoch 179/300\n",
      "455/455 [==============================] - 0s 153us/step - loss: 0.0927 - acc: 0.9736\n",
      "Epoch 180/300\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.0924 - acc: 0.9736\n",
      "Epoch 181/300\n",
      "455/455 [==============================] - 0s 180us/step - loss: 0.0922 - acc: 0.9736\n",
      "Epoch 182/300\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.0918 - acc: 0.9736\n",
      "Epoch 183/300\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.0915 - acc: 0.9736\n",
      "Epoch 184/300\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.0912 - acc: 0.9736\n",
      "Epoch 185/300\n",
      "455/455 [==============================] - 0s 284us/step - loss: 0.0910 - acc: 0.9736\n",
      "Epoch 186/300\n",
      "455/455 [==============================] - 0s 209us/step - loss: 0.0906 - acc: 0.9736\n",
      "Epoch 187/300\n",
      "455/455 [==============================] - 0s 151us/step - loss: 0.0903 - acc: 0.9736\n",
      "Epoch 188/300\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.0902 - acc: 0.9736\n",
      "Epoch 189/300\n",
      "455/455 [==============================] - 0s 160us/step - loss: 0.0898 - acc: 0.9736\n",
      "Epoch 190/300\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.0895 - acc: 0.9736\n",
      "Epoch 191/300\n",
      "455/455 [==============================] - 0s 171us/step - loss: 0.0892 - acc: 0.9736\n",
      "Epoch 192/300\n",
      "455/455 [==============================] - 0s 298us/step - loss: 0.0890 - acc: 0.9736\n",
      "Epoch 193/300\n",
      "455/455 [==============================] - 0s 179us/step - loss: 0.0887 - acc: 0.9736\n",
      "Epoch 194/300\n",
      "455/455 [==============================] - 0s 129us/step - loss: 0.0884 - acc: 0.9736\n",
      "Epoch 195/300\n",
      "455/455 [==============================] - 0s 165us/step - loss: 0.0882 - acc: 0.9736\n",
      "Epoch 196/300\n",
      "455/455 [==============================] - 0s 192us/step - loss: 0.0879 - acc: 0.9736\n",
      "Epoch 197/300\n",
      "455/455 [==============================] - 0s 192us/step - loss: 0.0877 - acc: 0.9736\n",
      "Epoch 198/300\n",
      "455/455 [==============================] - 0s 178us/step - loss: 0.0875 - acc: 0.9736\n",
      "Epoch 199/300\n",
      "455/455 [==============================] - 0s 142us/step - loss: 0.0872 - acc: 0.9736\n",
      "Epoch 200/300\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.0870 - acc: 0.9736\n",
      "Epoch 201/300\n",
      "455/455 [==============================] - 0s 244us/step - loss: 0.0867 - acc: 0.9736\n",
      "Epoch 202/300\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0865 - acc: 0.9736\n",
      "Epoch 203/300\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0863 - acc: 0.9736\n",
      "Epoch 204/300\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0860 - acc: 0.9736\n",
      "Epoch 205/300\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.0858 - acc: 0.9736\n",
      "Epoch 206/300\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.0856 - acc: 0.9736\n",
      "Epoch 207/300\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.0854 - acc: 0.9736\n",
      "Epoch 208/300\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0852 - acc: 0.9736\n",
      "Epoch 209/300\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.0850 - acc: 0.9736\n",
      "Epoch 210/300\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.0847 - acc: 0.9758\n",
      "Epoch 211/300\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.0845 - acc: 0.9758\n",
      "Epoch 212/300\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.0843 - acc: 0.9758\n",
      "Epoch 213/300\n",
      "455/455 [==============================] - 0s 213us/step - loss: 0.0841 - acc: 0.9758\n",
      "Epoch 214/300\n",
      "455/455 [==============================] - 0s 296us/step - loss: 0.0839 - acc: 0.9758\n",
      "Epoch 215/300\n",
      "455/455 [==============================] - 0s 198us/step - loss: 0.0837 - acc: 0.9758\n",
      "Epoch 216/300\n",
      "455/455 [==============================] - 0s 120us/step - loss: 0.0835 - acc: 0.9758\n",
      "Epoch 217/300\n",
      "455/455 [==============================] - 0s 162us/step - loss: 0.0833 - acc: 0.9758\n",
      "Epoch 218/300\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.0832 - acc: 0.9758\n",
      "Epoch 219/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 129us/step - loss: 0.0830 - acc: 0.9758\n",
      "Epoch 220/300\n",
      "455/455 [==============================] - 0s 177us/step - loss: 0.0827 - acc: 0.9758\n",
      "Epoch 221/300\n",
      "455/455 [==============================] - 0s 180us/step - loss: 0.0826 - acc: 0.9758\n",
      "Epoch 222/300\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.0824 - acc: 0.9758\n",
      "Epoch 223/300\n",
      "455/455 [==============================] - 0s 131us/step - loss: 0.0822 - acc: 0.9758\n",
      "Epoch 224/300\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.0820 - acc: 0.9758\n",
      "Epoch 225/300\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.0820 - acc: 0.9758\n",
      "Epoch 226/300\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.0817 - acc: 0.9758\n",
      "Epoch 227/300\n",
      "455/455 [==============================] - 0s 176us/step - loss: 0.0815 - acc: 0.9758\n",
      "Epoch 228/300\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.0813 - acc: 0.9758\n",
      "Epoch 229/300\n",
      "455/455 [==============================] - ETA: 0s - loss: 0.0615 - acc: 0.994 - 0s 204us/step - loss: 0.0812 - acc: 0.9758\n",
      "Epoch 230/300\n",
      "455/455 [==============================] - 0s 166us/step - loss: 0.0810 - acc: 0.9758\n",
      "Epoch 231/300\n",
      "455/455 [==============================] - 0s 151us/step - loss: 0.0808 - acc: 0.9758\n",
      "Epoch 232/300\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.0807 - acc: 0.9758\n",
      "Epoch 233/300\n",
      "455/455 [==============================] - 0s 178us/step - loss: 0.0805 - acc: 0.9758\n",
      "Epoch 234/300\n",
      "455/455 [==============================] - 0s 165us/step - loss: 0.0804 - acc: 0.9758\n",
      "Epoch 235/300\n",
      "455/455 [==============================] - ETA: 0s - loss: 0.0817 - acc: 0.975 - 0s 272us/step - loss: 0.0802 - acc: 0.9758\n",
      "Epoch 236/300\n",
      "455/455 [==============================] - 0s 212us/step - loss: 0.0801 - acc: 0.9758\n",
      "Epoch 237/300\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.0799 - acc: 0.9758\n",
      "Epoch 238/300\n",
      "455/455 [==============================] - 0s 184us/step - loss: 0.0797 - acc: 0.9758\n",
      "Epoch 239/300\n",
      "455/455 [==============================] - 0s 243us/step - loss: 0.0796 - acc: 0.9758\n",
      "Epoch 240/300\n",
      "455/455 [==============================] - 0s 193us/step - loss: 0.0795 - acc: 0.9758\n",
      "Epoch 241/300\n",
      "455/455 [==============================] - 0s 129us/step - loss: 0.0793 - acc: 0.9758\n",
      "Epoch 242/300\n",
      "455/455 [==============================] - 0s 264us/step - loss: 0.0792 - acc: 0.9758\n",
      "Epoch 243/300\n",
      "455/455 [==============================] - 0s 164us/step - loss: 0.0791 - acc: 0.9758\n",
      "Epoch 244/300\n",
      "455/455 [==============================] - 0s 166us/step - loss: 0.0789 - acc: 0.9758\n",
      "Epoch 245/300\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.0787 - acc: 0.9758\n",
      "Epoch 246/300\n",
      "455/455 [==============================] - 0s 173us/step - loss: 0.0787 - acc: 0.9758\n",
      "Epoch 247/300\n",
      "455/455 [==============================] - 0s 184us/step - loss: 0.0785 - acc: 0.9758\n",
      "Epoch 248/300\n",
      "455/455 [==============================] - 0s 160us/step - loss: 0.0783 - acc: 0.9758\n",
      "Epoch 249/300\n",
      "455/455 [==============================] - 0s 258us/step - loss: 0.0783 - acc: 0.9758\n",
      "Epoch 250/300\n",
      "455/455 [==============================] - 0s 220us/step - loss: 0.0781 - acc: 0.9758\n",
      "Epoch 251/300\n",
      "455/455 [==============================] - 0s 166us/step - loss: 0.0780 - acc: 0.9758\n",
      "Epoch 252/300\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.0778 - acc: 0.9758\n",
      "Epoch 253/300\n",
      "455/455 [==============================] - 0s 161us/step - loss: 0.0778 - acc: 0.9758\n",
      "Epoch 254/300\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.0776 - acc: 0.9758\n",
      "Epoch 255/300\n",
      "455/455 [==============================] - 0s 177us/step - loss: 0.0774 - acc: 0.9758\n",
      "Epoch 256/300\n",
      "455/455 [==============================] - 0s 248us/step - loss: 0.0774 - acc: 0.9758\n",
      "Epoch 257/300\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.0772 - acc: 0.9780\n",
      "Epoch 258/300\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.0771 - acc: 0.9780\n",
      "Epoch 259/300\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.0771 - acc: 0.9758\n",
      "Epoch 260/300\n",
      "455/455 [==============================] - 0s 168us/step - loss: 0.0769 - acc: 0.9780\n",
      "Epoch 261/300\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.0768 - acc: 0.9758\n",
      "Epoch 262/300\n",
      "455/455 [==============================] - 0s 366us/step - loss: 0.0766 - acc: 0.9780\n",
      "Epoch 263/300\n",
      "455/455 [==============================] - 0s 183us/step - loss: 0.0765 - acc: 0.9780\n",
      "Epoch 264/300\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.0764 - acc: 0.9780\n",
      "Epoch 265/300\n",
      "455/455 [==============================] - 0s 161us/step - loss: 0.0763 - acc: 0.9780\n",
      "Epoch 266/300\n",
      "455/455 [==============================] - 0s 148us/step - loss: 0.0762 - acc: 0.9780\n",
      "Epoch 267/300\n",
      "455/455 [==============================] - 0s 217us/step - loss: 0.0761 - acc: 0.9780\n",
      "Epoch 268/300\n",
      "455/455 [==============================] - 0s 239us/step - loss: 0.0760 - acc: 0.9780\n",
      "Epoch 269/300\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.0760 - acc: 0.9780\n",
      "Epoch 270/300\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.0757 - acc: 0.9780\n",
      "Epoch 271/300\n",
      "455/455 [==============================] - 0s 168us/step - loss: 0.0757 - acc: 0.9780\n",
      "Epoch 272/300\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.0755 - acc: 0.9780\n",
      "Epoch 273/300\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.0754 - acc: 0.9780\n",
      "Epoch 274/300\n",
      "455/455 [==============================] - 0s 176us/step - loss: 0.0753 - acc: 0.9780\n",
      "Epoch 275/300\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.0753 - acc: 0.9780\n",
      "Epoch 276/300\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.0752 - acc: 0.9780\n",
      "Epoch 277/300\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.0751 - acc: 0.9780\n",
      "Epoch 278/300\n",
      "455/455 [==============================] - 0s 78us/step - loss: 0.0750 - acc: 0.9780\n",
      "Epoch 279/300\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.0749 - acc: 0.9780\n",
      "Epoch 280/300\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.0748 - acc: 0.9780\n",
      "Epoch 281/300\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.0747 - acc: 0.9780\n",
      "Epoch 282/300\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.0746 - acc: 0.9780\n",
      "Epoch 283/300\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.0745 - acc: 0.9780\n",
      "Epoch 284/300\n",
      "455/455 [==============================] - 0s 119us/step - loss: 0.0744 - acc: 0.9780\n",
      "Epoch 285/300\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.0744 - acc: 0.9780\n",
      "Epoch 286/300\n",
      "455/455 [==============================] - 0s 409us/step - loss: 0.0742 - acc: 0.9780\n",
      "Epoch 287/300\n",
      "455/455 [==============================] - 0s 306us/step - loss: 0.0742 - acc: 0.9780\n",
      "Epoch 288/300\n",
      "455/455 [==============================] - 0s 184us/step - loss: 0.0741 - acc: 0.9780\n",
      "Epoch 289/300\n",
      "455/455 [==============================] - 0s 321us/step - loss: 0.0740 - acc: 0.9780\n",
      "Epoch 290/300\n",
      "455/455 [==============================] - 0s 190us/step - loss: 0.0739 - acc: 0.9780\n",
      "Epoch 291/300\n",
      "455/455 [==============================] - 0s 201us/step - loss: 0.0738 - acc: 0.9780\n",
      "Epoch 292/300\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.0738 - acc: 0.9780\n",
      "Epoch 293/300\n",
      "455/455 [==============================] - 0s 303us/step - loss: 0.0737 - acc: 0.9780\n",
      "Epoch 294/300\n",
      "455/455 [==============================] - 0s 185us/step - loss: 0.0736 - acc: 0.9780\n",
      "Epoch 295/300\n",
      "455/455 [==============================] - 0s 208us/step - loss: 0.0735 - acc: 0.9780\n",
      "Epoch 296/300\n",
      "455/455 [==============================] - 0s 177us/step - loss: 0.0734 - acc: 0.9780\n",
      "Epoch 297/300\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.0733 - acc: 0.9780\n",
      "Epoch 298/300\n",
      "455/455 [==============================] - 0s 148us/step - loss: 0.0733 - acc: 0.9780\n",
      "Epoch 299/300\n",
      "455/455 [==============================] - 0s 120us/step - loss: 0.0732 - acc: 0.9780\n",
      "Epoch 300/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 88us/step - loss: 0.0731 - acc: 0.9780\n",
      "[0.00852263] [0]\n",
      "[0.00951374] [0]\n",
      "[0.07309777] [0]\n",
      "[0.01137319] [0]\n",
      "[0.00635833] [0]\n",
      "[0.99179804] [1]\n",
      "[0.10567185] [0]\n",
      "[0.21883318] [0]\n",
      "[0.93368876] [0]\n",
      "[0.02104577] [0]\n",
      "[0.00658777] [0]\n",
      "[0.9979334] [1]\n",
      "[0.9953059] [1]\n",
      "[0.00726312] [0]\n",
      "[0.99804085] [1]\n",
      "[0.15180337] [0]\n",
      "[0.00658739] [0]\n",
      "[0.06515402] [0]\n",
      "[0.00698164] [0]\n",
      "[0.2610957] [0]\n",
      "[0.96976256] [1]\n",
      "[0.99638784] [1]\n",
      "[0.9779887] [1]\n",
      "[0.997959] [1]\n",
      "[0.99795365] [1]\n",
      "[0.00939307] [0]\n",
      "[0.01485825] [0]\n",
      "[0.00582969] [0]\n",
      "[0.01250684] [0]\n",
      "[0.9945861] [1]\n",
      "[0.08885536] [0]\n",
      "[0.99625397] [1]\n",
      "[0.22247127] [0]\n",
      "[0.997998] [1]\n",
      "[0.0204083] [0]\n",
      "[0.02468055] [0]\n",
      "[0.00789857] [0]\n",
      "[0.02388144] [0]\n",
      "[0.00616136] [0]\n",
      "[0.9978571] [1]\n",
      "[0.07602921] [0]\n",
      "[0.133391] [0]\n",
      "[0.3584404] [1]\n",
      "[0.96272445] [1]\n",
      "[0.2485154] [0]\n",
      "[0.00653735] [0]\n",
      "[0.0065859] [0]\n",
      "[0.00618532] [0]\n",
      "[0.880202] [1]\n",
      "[0.02303118] [0]\n",
      "[0.00598308] [0]\n",
      "[0.00658789] [0]\n",
      "[0.02829447] [0]\n",
      "[0.00655466] [0]\n",
      "[0.00652683] [0]\n",
      "[0.9980409] [1]\n",
      "[0.99214906] [1]\n",
      "[0.2803217] [1]\n",
      "[0.00658777] [0]\n",
      "[0.02293286] [0]\n",
      "[0.03835243] [0]\n",
      "[0.9939606] [1]\n",
      "[0.05825675] [0]\n",
      "[0.99678487] [1]\n",
      "[0.4362564] [1]\n",
      "[0.00608599] [0]\n",
      "[0.0091345] [0]\n",
      "[0.9968034] [1]\n",
      "[0.997475] [1]\n",
      "[0.05318937] [0]\n",
      "[0.07850942] [0]\n",
      "[0.0191561] [0]\n",
      "[0.08227193] [0]\n",
      "[0.03854272] [0]\n",
      "[0.09668952] [0]\n",
      "[0.99792135] [1]\n",
      "[0.9788785] [1]\n",
      "[0.87815726] [1]\n",
      "[0.00995892] [0]\n",
      "[0.0073843] [0]\n",
      "[0.01628366] [0]\n",
      "[0.00971991] [0]\n",
      "[0.01007378] [0]\n",
      "[0.00728798] [0]\n",
      "[0.991843] [1]\n",
      "[0.99804014] [1]\n",
      "[0.99673533] [1]\n",
      "[0.01329654] [0]\n",
      "[0.01150331] [0]\n",
      "[0.97890306] [1]\n",
      "[0.00654277] [0]\n",
      "[0.9584821] [1]\n",
      "[0.9971908] [1]\n",
      "[0.00833908] [0]\n",
      "[0.00623977] [0]\n",
      "[0.00842035] [0]\n",
      "[0.991288] [1]\n",
      "[0.97704184] [1]\n",
      "[0.1828039] [0]\n",
      "[0.13118044] [0]\n",
      "[0.9979236] [1]\n",
      "[0.05014154] [0]\n",
      "[0.99762964] [1]\n",
      "[0.99619806] [1]\n",
      "[0.0065724] [0]\n",
      "[0.01832369] [0]\n",
      "[0.9740323] [1]\n",
      "[0.9949287] [1]\n",
      "[0.6314678] [1]\n",
      "[0.0099265] [0]\n",
      "[0.01124215] [0]\n",
      "[0.00599226] [0]\n",
      "[0.99779934] [1]\n",
      "[0.0065522] [0]\n",
      "0.9649122807017544 0.023562790016173812\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, LSTM, RepeatVector, TimeDistributed\n",
    "#setting\n",
    "kval = 10\n",
    "itertot = 40\n",
    "sigma = 1.2\n",
    "itergd = 300\n",
    "def transforminput(param, center):\n",
    " newinput = np.zeros((len(param), len(center))).astype('float32')\n",
    " for i in range(len(param)):\n",
    "  for j in range(len(center)):\n",
    "   newinput[i,j] = np.exp(-(np.sum((param[i] - center[j])**2.0)**0.5) / sigma**2.0)\n",
    " return newinput\n",
    "def generatemodel(numparam):\n",
    " model = Sequential()\n",
    " model.add(Dense(1, input_dim=numparam, activation='sigmoid'))\n",
    "# model.add(Dense(10, activation='sigmoid'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    " # Compile model\n",
    " model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " return model\n",
    "#dividing data\n",
    "trainparam = X_train\n",
    "trainlabel = y_train\n",
    "testparam = X_test\n",
    "testlabel = y_test\n",
    "###############\n",
    "#normalization#\n",
    "###############\n",
    "std = np.zeros((len(trainparam[0]))).astype('float32')\n",
    "rata = np.zeros((len(trainparam[0]))).astype('float32')\n",
    "trainparamnorm = np.zeros(np.shape(trainparam))\n",
    "testparamnorm = np.zeros(np.shape(testparam))\n",
    "for i in range(len(trainparam[0])):\n",
    " std[i] = np.std(trainparam[:,i])\n",
    " rata[i] = np.mean(trainparam[:,i])\n",
    " trainparamnorm[:,i] = (trainparam[:,i] - rata[i]) / std[i]\n",
    " testparamnorm[:,i] = (testparam[:,i] - rata[i]) / std[i]\n",
    "###############\n",
    "#search k-mean#\n",
    "###############\n",
    "#init kmean\n",
    "kmean = np.zeros((kval, len(trainparamnorm[0])))\n",
    "for i in range(kval):\n",
    " for j in range(len(kmean[0])):\n",
    "  kmean[i,j] = random.uniform(min(trainparamnorm[:,j]),max(trainparamnorm[:,j]))\n",
    "#looping of real algorithm\n",
    "distmin = np.zeros((len(trainparamnorm)))\n",
    "for i in range(itertot):\n",
    " print ('iterasi ke', i)\n",
    " for j in range(len(distmin)):\n",
    "  #determine euclid distance\n",
    "  distall = np.sum((trainparamnorm[j] - kmean)**2.0, axis=1)**0.5\n",
    "  distmin[j] = np.argmin(distall)\n",
    "#search new k mean\n",
    " for j in range(kval):\n",
    "  clust = []\n",
    "  for k in range(len(distmin)):\n",
    "   if distmin[k] == j:\n",
    "    clust.append(trainparamnorm[k])\n",
    "  if len(clust) > 0:\n",
    "   kmean[j] = np.mean(np.asarray(clust), axis=0)\n",
    "#tranform our input\n",
    "newinput = transforminput(trainparamnorm, kmean)\n",
    "print (trainlabel)\n",
    "##########################\n",
    "#gradient descent session#\n",
    "##########################\n",
    "mod = generatemodel(kval)\n",
    "mod.fit(newinput, trainlabel, batch_size=20, epochs=itergd, verbose=1, shuffle=True)\n",
    "##################\n",
    "#predict session#\n",
    "##################\n",
    "#transform test data\n",
    "newinputtest = transforminput(testparamnorm, kmean)\n",
    "lifeprob = mod.predict(newinputtest)\n",
    "#######################\n",
    "#determine performance#\n",
    "#######################\n",
    "#determine biner accuracy\n",
    "binpred = np.zeros((len(lifeprob)))\n",
    "for i in range(len(lifeprob)):\n",
    " if lifeprob[i] > 0.5:\n",
    "  binpred[i] = 1.\n",
    "score = 0\n",
    "for i in range(len(testlabel)):\n",
    " if binpred[i] == testlabel[i]:\n",
    "  score += 1\n",
    "accbin = float(score) / float(len(testlabel))\n",
    "#determine brier score\n",
    "brierscore = 0\n",
    "for i in range(len(testlabel)):\n",
    " brierscore += (testlabel[i] - lifeprob[i])**2.0\n",
    "brierscore = brierscore / float(len(testlabel))\n",
    "for i in range(len(testlabel)):\n",
    " print (lifeprob[i], testlabel[i])\n",
    "print (accbin, brierscore[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Final_ECE_657_colab copy.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
